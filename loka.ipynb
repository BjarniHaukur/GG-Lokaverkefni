{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d94db90",
   "metadata": {},
   "source": [
    "# REI505M Machine Learning - Final project\n",
    "### Due: --------\n",
    "\n",
    "**Names**: Axel Kristj√°n Axelsson, Bjarni Haukur Bjarnason <br />\n",
    "**Email**: aka30@hi.is, bhb23@hi.is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ad1d8",
   "metadata": {},
   "source": [
    "**1. Image classification**\n",
    "\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9288b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "tf.executing_eagerly()\n",
    "\n",
    "\n",
    "from data_loader import MyDataLoader\n",
    "from neural_nets import NeuralNets\n",
    "from helper_funcs import *\n",
    "from my_dataset import parse_to_image, parse_and_augment\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "norm = (128,128)\n",
    "\n",
    "dl = MyDataLoader(\"flowers\", norm)\n",
    "nn = NeuralNets(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67c528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl.normalize_train_data()\n",
    "# dl.all_to_one()\n",
    "filenames = dl.get_all_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4580f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from my_dataset import create_dataset_from_files\n",
    "\n",
    "# filenames = dl.get_all_filenames()\n",
    "\n",
    "# NUM_FILES = len(filenames)\n",
    "# VAL_SIZE = 384\n",
    "# TEST_SIZE = 64\n",
    "\n",
    "# index_arr1 = np.random.choice(NUM_FILES, VAL_SIZE)\n",
    "# index_arr2 = np.random.choice(NUM_FILES-VAL_SIZE, TEST_SIZE)\n",
    "\n",
    "# val_files = filenames[index_arr1]\n",
    "# train_files = np.delete(filenames, index_arr1)\n",
    "# test_files = train_files[index_arr2]\n",
    "# train_files = np.delete(train_files, index_arr2)\n",
    "# NUM_FILES = len(filenames)\n",
    "\n",
    "# numpy_dump(train_files, \"small_train\")\n",
    "# numpy_dump(test_files, \"small_test\")\n",
    "# numpy_dump(val_files, \"small_val\")\n",
    "\n",
    "# train_files = numpy_load(\"train_files\")\n",
    "# test_files  = numpy_load(\"test_files\")\n",
    "# val_files   = numpy_load(\"val_files\")\n",
    "\n",
    "train_files = numpy_load(\"small_train\")\n",
    "test_files = numpy_load(\"small_test\")\n",
    "val_files = numpy_load(\"small_val\")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "WORKERS    = 16\n",
    "TEST_SIZE  = test_files.shape[0]\n",
    "VAL_SIZE   = val_files.shape[0]\n",
    "TRAIN_SIZE = train_files.shape[0]\n",
    "NUM_FILES  = TEST_SIZE + VAL_SIZE + TRAIN_SIZE\n",
    "\n",
    "\n",
    "NUM_TRAIN_STEPS = math.floor(TRAIN_SIZE/BATCH_SIZE)\n",
    "NUM_VAL_STEPS   = math.floor(VAL_SIZE/BATCH_SIZE)\n",
    "\n",
    "ds_train = create_dataset_from_files(train_files, batch_size=BATCH_SIZE, num_parallel_calls=WORKERS, augment=True)\n",
    "ds_val   = create_dataset_from_files(val_files, batch_size=BATCH_SIZE, num_parallel_calls=WORKERS, augment=True)\n",
    "ds_test  = create_dataset_from_files(test_files, batch_size=BATCH_SIZE, num_parallel_calls=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018b9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "  return (1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0)))#+0.5*tf.keras.metrics.mean_squared_error(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.model_i()\n",
    "model.compile(optimizer='rmsprop', loss=SSIMLoss, metrics=[\"accuracy\"])\n",
    "log_dir = \"logs/fit/\" + \"model_i\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "num_iters = 20\n",
    "\n",
    "test_images = ds_test.as_numpy_iterator().next()\n",
    "\n",
    "\n",
    "history_arr = np.ndarray(shape=(num_iters,), dtype=object)\n",
    "for i in range(num_iters):\n",
    "    history_arr[i] = model.fit(ds_train, epochs=5, steps_per_epoch=NUM_TRAIN_STEPS, validation_data=ds_val, validation_steps=NUM_VAL_STEPS, callbacks=[tensorboard_callback])\n",
    "    \n",
    "    if i%2==0:\n",
    "        save_model(model, f\"model_i_SSIMV2_{i}\", brave=True)\n",
    "\n",
    "    img_number = randint(0, BATCH_SIZE-1)\n",
    "    img = np.expand_dims(test_images[0][img_number], 0)\n",
    "    pred = model.predict(img)\n",
    "    save_images(img , map_from(pred), name=\"model_i_SSIMV2\", enumerate=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from helper_funcs import *\n",
    "\n",
    "# new_arr = np.ndarray(shape=(30,), dtype=object)\n",
    "# new_arr[:10] = history_arr\n",
    "# new_arr[10:] = history_arr2\n",
    "\n",
    "plot_acc_and_loss(history_arr, title=\"Model_i with 100% SSIM loss\", name=\"model_i_SSIMV2\", save=True, figsize=(10,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"model_i_SSIM_10\", custom={'SSIMLoss':SSIMLoss})\n",
    "# model = gan.get_generator()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "725371bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_i_SSIMV219\", custom={'SSIMLoss':SSIMLoss})\n",
    "# model = gan.get_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54f874ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# model_e14 frekar gott general skill, model_e40 gott en of miklir litir\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "# model_i_SSIM19 er skringilega gott\n",
    "####################################################################################\n",
    "\n",
    "# save_model(model, \"model_e40\")\n",
    "\n",
    "\n",
    "# img_numbers = np.random.choice(size, 5)\n",
    "# test_image = X_test[img_numbers]\n",
    "\n",
    "test_image = ds_test.as_numpy_iterator().next()\n",
    "\n",
    "\n",
    "\n",
    "num_images = 32\n",
    "\n",
    "# grey = test_image[0][[14, 16, 18, 30,31,32,32,34,35,36,37,38,39]]\n",
    "# ab   = test_image[1][[14, 16, 18, 30,31,32,32,34,35,36,37,38,39]]\n",
    "\n",
    "grey = test_image[0][:num_images]\n",
    "ab   = test_image[1][:num_images]\n",
    "none_arr = np.zeros(shape=(num_images, norm[0], norm[1], 2))\n",
    "\n",
    "pred = model.predict(grey)\n",
    "# save_images(grey, none_arr, name=\"bw\")\n",
    "save_images(grey, map_from(pred), name=\"fake\", enhance=1.2)\n",
    "save_images(grey, map_from(ab), name=\"real\")\n",
    "# save_images(grey, map_from(ab), name=\"rgb\")\n",
    "# show_images(grey, map_from(ab))\n",
    "# show_images(grey, map_from(pred), enhance=1.2)\n",
    "# show_images(grey, map_from(ab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e751cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "iter = ds_test.as_numpy_iterator()\n",
    "test_image = iter.next()\n",
    "\n",
    "num_images = 10\n",
    "\n",
    "grey = test_image[0][:num_images]\n",
    "ab   = test_image[1][:num_images]\n",
    "pred = model.predict(grey)\n",
    "for i in range(num_images):\n",
    "    rand = randint(0, 1)\n",
    "    if rand:\n",
    "        show_images(grey[i:i+1], map_from(ab[i:i+1]), enhance=0.8)\n",
    "    else:\n",
    "        show_images(grey[i:i+1], map_from(pred[i:i+1]), enhance=1.2)\n",
    "    print(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de146611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan import MyGAN\n",
    "gan = MyGAN(ds_train, ds_val, nn.generator_b(), nn.discriminator_a())\n",
    "# try:\n",
    "#     trained = gan.is_trained()\n",
    "#     if not trained:\n",
    "#         gan = MyGAN(ds_train, ds_val, nn.generator_b(), nn.discriminator_b())\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775529b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "___________________________ Epoch 1 ______________________\n",
      "Generator loss:         0.689\n",
      "Generator val loss:     0.693\n",
      "Discriminator loss:     1.387\n",
      "Discriminator val loss: 1.386\n",
      "Validating...\n",
      "___________________________ Epoch 2 ______________________\n",
      "Generator loss:         0.693\n",
      "Generator val loss:     0.693\n",
      "Discriminator loss:     1.386\n",
      "Discriminator val loss: 1.386\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "num_iters = 10\n",
    "\n",
    "test_images = ds_test.as_numpy_iterator().next()\n",
    "\n",
    "# gan.train_individually(2, 12, NUM_TRAIN_STEPS, NUM_VAL_STEPS)\n",
    "\n",
    "for i in range(num_iters):\n",
    "    gan.fit(num_epochs=5, num_train_steps=NUM_TRAIN_STEPS, num_val_steps=NUM_VAL_STEPS)\n",
    "    \n",
    "    model = gan.get_generator()\n",
    "\n",
    "    img_number = randint(0, BATCH_SIZE-1)\n",
    "    img = np.expand_dims(test_images[0][img_number], 0)\n",
    "    pred = model(img)\n",
    "    save_images(img , map_from(pred), name=\"gan\", enumerate=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "598d67ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x166c951b520>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))\n",
    "print(val[0])\n",
    "plt.plot(val[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65d87dbd84d6699b6249583833f5a2128eb89a67d50c6406a8848397791798e4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('tf2.6.0': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
