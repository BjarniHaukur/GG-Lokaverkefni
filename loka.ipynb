{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d94db90",
   "metadata": {},
   "source": [
    "# REI505M Machine Learning - Final project\n",
    "### Due: --------\n",
    "\n",
    "**Names**: Axel Kristj√°n Axelsson, Bjarni Haukur Bjarnason <br />\n",
    "**Email**: aka30@hi.is, bhb23@hi.is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ad1d8",
   "metadata": {},
   "source": [
    "**1. Image classification**\n",
    "\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9288b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "from data_loader import MyDataLoader\n",
    "from neural_nets import NeuralNets\n",
    "from helper_funcs import *\n",
    "from my_dataset import parse_to_image\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "norm = (128,128)\n",
    "\n",
    "dl = MyDataLoader(\"combine3\", norm)\n",
    "nn = NeuralNets(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a909dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = dl.get_all_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaeda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.isfile(filenames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = dl.numpy_load(\"filenames\")\n",
    "print(file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4580f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "#REPEAT_COUNT = 1\n",
    "PREFETCH_SIZE = 4\n",
    "WORKERS = 8\n",
    "TEST_SIZE = 1000\n",
    "VAL_SIZE = 2000\n",
    "\n",
    "filenames = dl.get_all_filenames()\n",
    "ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "\n",
    "ds = ds.shuffle(buffer_size=len(filenames))#.repeat(REPEAT_COUNT)\n",
    "\n",
    "ds = ds.map(parse_to_image, num_parallel_calls=WORKERS)\n",
    "\n",
    "ds = ds.repeat()\n",
    "\n",
    "ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "ds = ds.prefetch(buffer_size=PREFETCH_SIZE)\n",
    "\n",
    "ds_test  = ds.take(TEST_SIZE)\n",
    "ds_val   = ds.skip(TEST_SIZE).take(VAL_SIZE)\n",
    "ds_train = ds.skip(TEST_SIZE + VAL_SIZE)\n",
    "\n",
    "# ds_train = ds_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# ds_train = ds_train.prefetch(PREFETCH_SIZE)\n",
    "\n",
    "# ds_val   = ds.skip(TEST_SIZE).take(VAL_SIZE)\n",
    "# ds_train = ds.skip(TEST_SIZE + VAL_SIZE)\n",
    "\n",
    "# ds_train = ds_train.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1270dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 128, 128, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 32, 32, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 32, 32, 128)       295040    \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 64, 64, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 64, 64, 64)        73792     \n",
      "                                                                 \n",
      " up_sampling2d_15 (UpSamplin  (None, 128, 128, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 128, 128, 2)       1154      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,495,490\n",
      "Trainable params: 1,495,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nn.model_e()\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d7e0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=10, steps_per_epoch=64)#, validation_data=ds_val, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f874ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = ds.as_numpy_iterator().next()\n",
    "X = np.expand_dims(bla[0][0], 0)\n",
    "\n",
    "print(X.shape)\n",
    "pred = model.predict(X)\n",
    "\n",
    "show_images(X, map_from(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.normalize_train_data(norm_size=norm)\n",
    "\n",
    "try:\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "X, y = dl.get_lab_data()\n",
    "dl.numpy_dump(X, \"X\")\n",
    "dl.numpy_dump(y, \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.squeeze(dl.numpy_load(\"X\"))\n",
    "X = dl.numpy_load(\"X\") # 0-1\n",
    "y = dl.numpy_load(\"y\") # -1 - 1\n",
    "X_lab = X\n",
    "y_lab = map_to(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.all_to_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = np.zeros(shape=(1,1,2,2))\n",
    "minmax[0,0,0,0] = np.max(y[:,:,:,0])\n",
    "minmax[0,0,1,0] = np.min(y[:,:,:,0])\n",
    "minmax[0,0,0,1] = np.max(y[:,:,:,1])\n",
    "minmax[0,0,1,1] = np.min(y[:,:,:,1])\n",
    "\n",
    "# print(np.max(y))\n",
    "# print(np.min(y))\n",
    "# print(np.max(y_lab))\n",
    "# print(np.min(y_lab))\n",
    "# test = map_from(y_lab, y)\n",
    "# print(np.max(test))\n",
    "# print(np.min(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lab, y_lab, test_size = 0.3, random_state = 3)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.33, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e49d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import randint\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "\n",
    "# ?GANS svona\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "log_dir = \"logs/fit/\" + \"model_e\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#model = load_model(\"model_e\")\n",
    "model = nn.autoencoder()\n",
    "model.compile(optimizer=RMSprop(), loss=MeanSquaredError())\n",
    "\n",
    "\n",
    "percent = 0.6\n",
    "size = X_train.shape[0]\n",
    "for i in range(10):\n",
    "    rand_array = np.random.choice(size, int(percent*size))\n",
    "    X_bla = X_train[rand_array]\n",
    "    y_bla = y_train[rand_array]\n",
    "    model.fit(X_bla, y_bla, batch_size = 64, epochs = 5, validation_data=(X_val, y_val), callbacks=[tensorboard_callback])#, callbacks=[callback])\n",
    "#save_model(model, \"model_e\", brave=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89be258",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 1\n",
    "size = X_train.shape[0]\n",
    "rand_array = np.random.choice(size, int(percent*size))\n",
    "X_bla = X_train[rand_array]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500689da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "log_dir = \"logs/fit/\" + \"model_e_2\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu,True)\n",
    "\n",
    "\n",
    "model = nn.model_f()\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from sys import getsizeof\n",
    "batch_size = 512\n",
    "train_size = X_train.shape[0]\n",
    "\n",
    "num_batches = floor(train_size/batch_size)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "data_batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "print(getsizeof(data_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for i in range(num_epochs):\n",
    "    data_batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "    model.fit(data_batches, epochs=1, batch_size=32, validation_data=(X_val, y_val),\n",
    "                  callbacks=[tensorboard_callback], workers=16)\n",
    "    \n",
    "\n",
    "    img_number = randint(0, train_size-1)\n",
    "    test_image = np.expand_dims(X_test[img_number], 0)\n",
    "    pred = model.predict(test_image)\n",
    "    save_images(test_image, map_from(pred, minmax), name=\"model_e\", enumerate=i)\n",
    "    save_model(model, \"model_f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # model.fit(x=X_bla, y=y_bla, epochs=10, batch_size=32, validation_data=(X_val, y_val),\n",
    "    #           callbacks=[tensorboard_callback],\n",
    "    #           use_multiprocessing=True, workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19661a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"new_model\")\n",
    "minmax = np.zeros(shape=(1,1,2,2))\n",
    "minmax[0,0,0,0] = np.max(y[:,:,:,0])\n",
    "minmax[0,0,1,0] = np.min(y[:,:,:,0])\n",
    "minmax[0,0,0,1] = np.max(y[:,:,:,1])\n",
    "minmax[0,0,1,1] = np.min(y[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "rand_array = np.random.choice(X_test.shape[0], 3)\n",
    "pred = model.predict(X_test[rand_array])\n",
    "none_arr = np.zeros(shape=(3,128,128,2))\n",
    "show_images(X_test[rand_array], none_arr)\n",
    "show_images(X_test[rand_array], map_from(pred, minmax), enhance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"model_e_3\", brave=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modell = load_model(\"model_e\")\n",
    "# none_arr = np.zeros(shape=(3, 128, 128, 2))\n",
    "# modell = load_model(\"model_e_2\")\n",
    "rand_array = np.random.choice(X_test.shape[0], 3)\n",
    "pred = model.predict(X_test[rand_array])\n",
    "show_images(X_test[rand_array], map_from(y_test[rand_array], minmax))\n",
    "show_images(X_test[rand_array], map_from(pred, minmax), enhance=True)\n",
    "# save_images(X_test[rand_array], map_from(pred, y), name=\"pred\", enhance=True)\n",
    "# save_images(X_test[rand_array], map_from(y_test[rand_array], y), name=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.shape)\n",
    "print(np.max(pred))\n",
    "print(np.min(pred))\n",
    "new = map_from(pred, y_train)\n",
    "print(np.max(new))\n",
    "print(np.min(new))\n",
    "# show_images(X_test[rand_array], map_from(pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_lab.shape)\n",
    "print(y_lab.shape)\n",
    "print(np.max(X_lab))\n",
    "print(np.max(y_lab))\n",
    "print(np.min(X_lab))\n",
    "print(np.min(y_lab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65383f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=30, fill_mode='nearest',\n",
    "                             width_shift_range=0.2, height_shift_range=0.2,\n",
    "                             horizontal_flip=True, vertical_flip=True,\n",
    "                             brightness_range=[0.4,1.5],\n",
    "                             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da48f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_funcs import *\n",
    "arr = y_train[:10]\n",
    "print(type(arr[0,0,0,0]))\n",
    "print(np.max(arr))\n",
    "print(np.min(arr))\n",
    "\n",
    "test = map_to(arr)\n",
    "print(type(test[0,0,0,0]))\n",
    "print(np.max(test))\n",
    "print(np.min(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "baka = map_from(test, arr)\n",
    "print(type(baka[0,0,0,0]))\n",
    "print(np.max(baka))\n",
    "print(np.min(baka))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = np.zeros(shape=(10, 128, 128, 3))\n",
    "images[:,:,:,0] = np.squeeze(X_train[:10], -1)\n",
    "images[:,:,:,1:] = y_train[:10]\n",
    "datagen = ImageDataGenerator(rotation_range=30, fill_mode='nearest',\n",
    "                             width_shift_range=0.2, height_shift_range=0.2,\n",
    "                             horizontal_flip=True, vertical_flip=True\n",
    ")\n",
    "image_it = datagen.flow(images, batch_size=10, shuffle=True)\n",
    "\n",
    "X_next = image_it.next()[:,:,:,0]\n",
    "y_next = image_it.next()[:,:,:,1:]\n",
    "X_bla = np.expand_dims(np.array(X_next), -1)\n",
    "y_bla = np.array(y_next)\n",
    "print(X_bla.shape)\n",
    "print(y_bla.shape)\n",
    "print(np.max(y_bla))\n",
    "print(np.min(y_bla))\n",
    "y_bla = map_from(y_bla, y)\n",
    "print(np.max(y_bla))\n",
    "print(np.min(y_bla))\n",
    "show_images(X_bla, y_bla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "\n",
    "log_dir = \"logs/fit/\" + \"model_e_2\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_number = 42\n",
    "test_image = np.expand_dims(X_test[img_number], 0)\n",
    "\n",
    "data_gen_args = dict(rotation_range=30, fill_mode='nearest',\n",
    "                     width_shift_range=0.2, height_shift_range=0.2,\n",
    "                     horizontal_flip=True, vertical_flip=True,\n",
    "                     shear_range=0.3\n",
    ")\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed = 1337\n",
    "image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow(X_train, seed = seed, batch_size=64)\n",
    "mask_generator = image_datagen.flow(y_train, seed = seed, batch_size=64)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090884cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = (128, 128, 1)\n",
    "# batch_size = 32\n",
    "# kernel_size = 3\n",
    "# latent_dim = 256\n",
    "# layer_filters = [64, 128, 256]\n",
    "# layer_filters = layer_filters[::-1]\n",
    "\n",
    "# inputs = Input(shape = input_shape)\n",
    "# x = inputs\n",
    "# for filters in layer_filters:\n",
    "#     x = Conv2D(filters = filters,\n",
    "#         kernel_size = kernel_size,\n",
    "#         strides = 2,\n",
    "#         activation ='relu',\n",
    "#         padding ='same')(x)\n",
    "  \n",
    "# shape = K.int_shape(x)\n",
    "# x = Flatten()(x)\n",
    "# latent = Dense(latent_dim, name ='latent_vector')(x)\n",
    "# encoder = Model(inputs, latent, name ='encoder')\n",
    "\n",
    "# latent_inputs = Input(shape =(latent_dim, ), name ='decoder_input')\n",
    "# x = Dense(shape[1]*shape[2]*shape[3])(latent_inputs)\n",
    "# x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "# # stack of Conv2DTranspose(256)-Conv2DTranspose(128)-\n",
    "# # Conv2DTranspose(64)\n",
    "# for filters in layer_filters[::-1]:\n",
    "#     x = Conv2DTranspose(filters = filters,\n",
    "#                         kernel_size = kernel_size,\n",
    "#                         strides = 2,\n",
    "#                         activation ='relu',\n",
    "#                         padding ='same')(x)\n",
    "#     outputs = Conv2DTranspose(filters = 2,\n",
    "#                             kernel_size = kernel_size,\n",
    "#                             activation ='sigmoid',\n",
    "#                             padding ='same',\n",
    "#                             name ='decoder_output')(x)\n",
    "#     decoder = Model(latent_inputs, outputs, name ='decoder')\n",
    "\n",
    "#     autoencoder = Model(inputs, decoder(encoder(inputs)),\n",
    "#                     name ='autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7939752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gen_args = dict(rotation_range=30, fill_mode='nearest',\n",
    "#                      width_shift_range=0.2, height_shift_range=0.2,\n",
    "#                      horizontal_flip=True, vertical_flip=True,\n",
    "#                      shear_range=0.3\n",
    "# )\n",
    "# image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "# mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# seed = 1337\n",
    "# image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "# mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "# image_generator = image_datagen.flow(X_train, seed = seed, batch_size=64)\n",
    "# mask_generator = image_datagen.flow(y_train, seed = seed, batch_size=64)\n",
    "\n",
    "# train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "\n",
    "# # model = nn.autoencoder()\n",
    "# # model.compile(optimizer=RMSprop(), loss=MeanSquaredError(), metrics=[\"accuracy\"])\n",
    "# # model = nn.model_s()\n",
    "# # model.compile(optimizer='rmsprop', loss='mse', metrics=[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65d87dbd84d6699b6249583833f5a2128eb89a67d50c6406a8848397791798e4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('tf2.6.0': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
