{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d94db90",
   "metadata": {},
   "source": [
    "# REI505M Machine Learning - Final project\n",
    "### Due: --------\n",
    "\n",
    "**Names**: Axel Kristján Axelsson, Bjarni Haukur Bjarnason <br />\n",
    "**Email**: aka30@hi.is, bhb23@hi.is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ad1d8",
   "metadata": {},
   "source": [
    "**1. Image classification**\n",
    "\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9288b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "from data_loader import MyDataLoader\n",
    "from neural_nets import NeuralNets\n",
    "from helper_funcs import *\n",
    "from my_dataset import parse_to_image\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "norm = (128,128)\n",
    "\n",
    "dl = MyDataLoader(\"combine3\", norm)\n",
    "nn = NeuralNets(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a909dd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\\y\\0\\buttercup2.jpg\n"
     ]
    }
   ],
   "source": [
    "filenames = dl.get_all_filenames()\n",
    "filenames.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4580f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "PREFETCH_SIZE = 16\n",
    "TEST_SIZE = 1000\n",
    "VAL_SIZE = 2000\n",
    "\n",
    "filenames = dl.get_all_filenames()\n",
    "ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "\n",
    "ds = ds.shuffle(buffer_size=len(filenames))\n",
    "\n",
    "ds = ds.map(parse_to_image, num_parallel_calls=8)\n",
    "\n",
    "ds = ds.prefetch(PREFETCH_SIZE)\n",
    "\n",
    "ds_test  = ds.take(TEST_SIZE)\n",
    "ds_val   = ds.skip(TEST_SIZE).take(VAL_SIZE)\n",
    "ds_train = ds.skip(TEST_SIZE + VAL_SIZE)\n",
    "\n",
    "ds_train = ds_train.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1270dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 128, 128, 64)      640       \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 256, 256, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 256, 256, 128)     73856     \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 512, 512, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 512, 512, 128)     147584    \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 512, 512, 256)     295168    \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 1024, 1024, 256)  0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 1024, 1024, 256)   590080    \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 2048, 2048, 256)  0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 1024, 1024, 512)   1180160   \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 512, 512, 256)     1179904   \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 256, 256, 128)     295040    \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 128, 128, 64)      73792     \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 128, 128, 2)       1154      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,874,306\n",
      "Trainable params: 3,874,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nn.model_f()\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=[\"accuracy\"])\n",
    "model.fit(ds_train, epochs=10, batch_size=32, validation_data=ds_val, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d7e0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,128,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/conv2d_13/Relu\n (defined at C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\backend.py:4867)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4784]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/conv2d_13/Relu:\nIn[0] sequential_1/conv2d_13/BiasAdd (defined at C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\layers\\convolutional.py:264)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\bjarn\\AppData\\Local\\Temp/ipykernel_17628/679752444.py\", line 1, in <module>\n>>>     model.fit(ds_train, epochs=10, batch_size=32, validation_data=ds_val, workers=16)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 273, in call\n>>>     return self.activation(outputs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\activations.py\", line 311, in relu\n>>>     return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\backend.py\", line 4867, in relu\n>>>     x = tf.nn.relu(x)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17628/679752444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,128,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/conv2d_13/Relu\n (defined at C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\backend.py:4867)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4784]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/conv2d_13/Relu:\nIn[0] sequential_1/conv2d_13/BiasAdd (defined at C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\layers\\convolutional.py:264)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\bjarn\\AppData\\Local\\Temp/ipykernel_17628/679752444.py\", line 1, in <module>\n>>>     model.fit(ds_train, epochs=10, batch_size=32, validation_data=ds_val, workers=16)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 273, in call\n>>>     return self.activation(outputs)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\activations.py\", line 311, in relu\n>>>     return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n>>> \n>>>   File \"C:\\Users\\bjarn\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages\\keras\\backend.py\", line 4867, in relu\n>>>     x = tf.nn.relu(x)\n>>> "
     ]
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=10, batch_size=32, validation_data=ds_val, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f874ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "image = tf.io.read_file(\"model_e1.jpg\")\n",
    "image = tf.image.decode_jpeg(image)\n",
    "image = tf.image.convert_image_dtype(image, tf.float16)\n",
    "image = tfio.experimental.color.rgb_to_lab(image)\n",
    "print(image[:,:,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee46fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [02:26<00:00,  1.31s/it]\n",
      "100%|██████████| 112/112 [05:15<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "dl.normalize_train_data(norm_size=norm)\n",
    "\n",
    "try:\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "X, y = dl.get_lab_data()\n",
    "dl.numpy_dump(X, \"X\")\n",
    "dl.numpy_dump(y, \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b32dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.squeeze(dl.numpy_load(\"X\"))\n",
    "X = dl.numpy_load(\"X\") # 0-1\n",
    "y = dl.numpy_load(\"y\") # -1 - 1\n",
    "X_lab = X\n",
    "y_lab = map_to(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.all_to_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff7d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = np.zeros(shape=(1,1,2,2))\n",
    "minmax[0,0,0,0] = np.max(y[:,:,:,0])\n",
    "minmax[0,0,1,0] = np.min(y[:,:,:,0])\n",
    "minmax[0,0,0,1] = np.max(y[:,:,:,1])\n",
    "minmax[0,0,1,1] = np.min(y[:,:,:,1])\n",
    "\n",
    "# print(np.max(y))\n",
    "# print(np.min(y))\n",
    "# print(np.max(y_lab))\n",
    "# print(np.min(y_lab))\n",
    "# test = map_from(y_lab, y)\n",
    "# print(np.max(test))\n",
    "# print(np.min(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d5beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lab, y_lab, test_size = 0.3, random_state = 3)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.33, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e49d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import randint\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "\n",
    "# ?GANS svona\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "log_dir = \"logs/fit/\" + \"model_e\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#model = load_model(\"model_e\")\n",
    "model = nn.autoencoder()\n",
    "model.compile(optimizer=RMSprop(), loss=MeanSquaredError())\n",
    "\n",
    "\n",
    "percent = 0.6\n",
    "size = X_train.shape[0]\n",
    "for i in range(10):\n",
    "    rand_array = np.random.choice(size, int(percent*size))\n",
    "    X_bla = X_train[rand_array]\n",
    "    y_bla = y_train[rand_array]\n",
    "    model.fit(X_bla, y_bla, batch_size = 64, epochs = 5, validation_data=(X_val, y_val), callbacks=[tensorboard_callback])#, callbacks=[callback])\n",
    "#save_model(model, \"model_e\", brave=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89be258",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 1\n",
    "size = X_train.shape[0]\n",
    "rand_array = np.random.choice(size, int(percent*size))\n",
    "X_bla = X_train[rand_array]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500689da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      640       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 512, 512, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 512, 512, 128)     147584    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 512, 512, 256)     295168    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 1024, 1024, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1024, 1024, 256)   590080    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 2048, 2048, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1024, 1024, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 512, 512, 256)     1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 128)     295040    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 128, 2)       1154      \n",
      "=================================================================\n",
      "Total params: 3,874,306\n",
      "Trainable params: 3,874,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "log_dir = \"logs/fit/\" + \"model_e_2\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu,True)\n",
    "\n",
    "\n",
    "model = nn.model_f()\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6066e8da",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4816/367579787.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdata_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    683\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \"\"\"\n\u001b[1;32m--> 685\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   3842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3843\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3844\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3845\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3846\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    127\u001b[0m           \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m           normalized_components.append(\n\u001b[1;32m--> 129\u001b[1;33m               ops.convert_to_tensor(t, name=\"component_%d\" % i, dtype=dtype))\n\u001b[0m\u001b[0;32m    130\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpack_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "from sys import getsizeof\n",
    "batch_size = 512\n",
    "train_size = X_train.shape[0]\n",
    "\n",
    "num_batches = floor(train_size/batch_size)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "data_batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "print(getsizeof(data_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afe0561",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[512,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/conv2d/Relu-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1671]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4816/3805533697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     model.fit(data_batches, epochs=1, batch_size=32, validation_data=(X_val, y_val),\n\u001b[0m\u001b[0;32m      6\u001b[0m                   callbacks=[tensorboard_callback], workers=16)\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[512,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/conv2d/Relu-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1671]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for i in range(num_epochs):\n",
    "    data_batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "    model.fit(data_batches, epochs=1, batch_size=32, validation_data=(X_val, y_val),\n",
    "                  callbacks=[tensorboard_callback], workers=16)\n",
    "    \n",
    "\n",
    "    img_number = randint(0, train_size-1)\n",
    "    test_image = np.expand_dims(X_test[img_number], 0)\n",
    "    pred = model.predict(test_image)\n",
    "    save_images(test_image, map_from(pred, minmax), name=\"model_e\", enumerate=i)\n",
    "    save_model(model, \"model_f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # model.fit(x=X_bla, y=y_bla, epochs=10, batch_size=32, validation_data=(X_val, y_val),\n",
    "    #           callbacks=[tensorboard_callback],\n",
    "    #           use_multiprocessing=True, workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19661a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"new_model\")\n",
    "minmax = np.zeros(shape=(1,1,2,2))\n",
    "minmax[0,0,0,0] = np.max(y[:,:,:,0])\n",
    "minmax[0,0,1,0] = np.min(y[:,:,:,0])\n",
    "minmax[0,0,0,1] = np.max(y[:,:,:,1])\n",
    "minmax[0,0,1,1] = np.min(y[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "rand_array = np.random.choice(X_test.shape[0], 3)\n",
    "pred = model.predict(X_test[rand_array])\n",
    "none_arr = np.zeros(shape=(3,128,128,2))\n",
    "show_images(X_test[rand_array], none_arr)\n",
    "show_images(X_test[rand_array], map_from(pred, minmax), enhance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"model_e_3\", brave=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modell = load_model(\"model_e\")\n",
    "# none_arr = np.zeros(shape=(3, 128, 128, 2))\n",
    "# modell = load_model(\"model_e_2\")\n",
    "rand_array = np.random.choice(X_test.shape[0], 3)\n",
    "pred = model.predict(X_test[rand_array])\n",
    "show_images(X_test[rand_array], map_from(y_test[rand_array], minmax))\n",
    "show_images(X_test[rand_array], map_from(pred, minmax), enhance=True)\n",
    "# save_images(X_test[rand_array], map_from(pred, y), name=\"pred\", enhance=True)\n",
    "# save_images(X_test[rand_array], map_from(y_test[rand_array], y), name=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.shape)\n",
    "print(np.max(pred))\n",
    "print(np.min(pred))\n",
    "new = map_from(pred, y_train)\n",
    "print(np.max(new))\n",
    "print(np.min(new))\n",
    "# show_images(X_test[rand_array], map_from(pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_lab.shape)\n",
    "print(y_lab.shape)\n",
    "print(np.max(X_lab))\n",
    "print(np.max(y_lab))\n",
    "print(np.min(X_lab))\n",
    "print(np.min(y_lab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65383f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=30, fill_mode='nearest',\n",
    "                             width_shift_range=0.2, height_shift_range=0.2,\n",
    "                             horizontal_flip=True, vertical_flip=True,\n",
    "                             brightness_range=[0.4,1.5],\n",
    "                             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da48f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_funcs import *\n",
    "arr = y_train[:10]\n",
    "print(type(arr[0,0,0,0]))\n",
    "print(np.max(arr))\n",
    "print(np.min(arr))\n",
    "\n",
    "test = map_to(arr)\n",
    "print(type(test[0,0,0,0]))\n",
    "print(np.max(test))\n",
    "print(np.min(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "baka = map_from(test, arr)\n",
    "print(type(baka[0,0,0,0]))\n",
    "print(np.max(baka))\n",
    "print(np.min(baka))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = np.zeros(shape=(10, 128, 128, 3))\n",
    "images[:,:,:,0] = np.squeeze(X_train[:10], -1)\n",
    "images[:,:,:,1:] = y_train[:10]\n",
    "datagen = ImageDataGenerator(rotation_range=30, fill_mode='nearest',\n",
    "                             width_shift_range=0.2, height_shift_range=0.2,\n",
    "                             horizontal_flip=True, vertical_flip=True\n",
    ")\n",
    "image_it = datagen.flow(images, batch_size=10, shuffle=True)\n",
    "\n",
    "X_next = image_it.next()[:,:,:,0]\n",
    "y_next = image_it.next()[:,:,:,1:]\n",
    "X_bla = np.expand_dims(np.array(X_next), -1)\n",
    "y_bla = np.array(y_next)\n",
    "print(X_bla.shape)\n",
    "print(y_bla.shape)\n",
    "print(np.max(y_bla))\n",
    "print(np.min(y_bla))\n",
    "y_bla = map_from(y_bla, y)\n",
    "print(np.max(y_bla))\n",
    "print(np.min(y_bla))\n",
    "show_images(X_bla, y_bla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "\n",
    "log_dir = \"logs/fit/\" + \"model_e_2\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_number = 42\n",
    "test_image = np.expand_dims(X_test[img_number], 0)\n",
    "\n",
    "data_gen_args = dict(rotation_range=30, fill_mode='nearest',\n",
    "                     width_shift_range=0.2, height_shift_range=0.2,\n",
    "                     horizontal_flip=True, vertical_flip=True,\n",
    "                     shear_range=0.3\n",
    ")\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed = 1337\n",
    "image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow(X_train, seed = seed, batch_size=64)\n",
    "mask_generator = image_datagen.flow(y_train, seed = seed, batch_size=64)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090884cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = (128, 128, 1)\n",
    "# batch_size = 32\n",
    "# kernel_size = 3\n",
    "# latent_dim = 256\n",
    "# layer_filters = [64, 128, 256]\n",
    "# layer_filters = layer_filters[::-1]\n",
    "\n",
    "# inputs = Input(shape = input_shape)\n",
    "# x = inputs\n",
    "# for filters in layer_filters:\n",
    "#     x = Conv2D(filters = filters,\n",
    "#         kernel_size = kernel_size,\n",
    "#         strides = 2,\n",
    "#         activation ='relu',\n",
    "#         padding ='same')(x)\n",
    "  \n",
    "# shape = K.int_shape(x)\n",
    "# x = Flatten()(x)\n",
    "# latent = Dense(latent_dim, name ='latent_vector')(x)\n",
    "# encoder = Model(inputs, latent, name ='encoder')\n",
    "\n",
    "# latent_inputs = Input(shape =(latent_dim, ), name ='decoder_input')\n",
    "# x = Dense(shape[1]*shape[2]*shape[3])(latent_inputs)\n",
    "# x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "# # stack of Conv2DTranspose(256)-Conv2DTranspose(128)-\n",
    "# # Conv2DTranspose(64)\n",
    "# for filters in layer_filters[::-1]:\n",
    "#     x = Conv2DTranspose(filters = filters,\n",
    "#                         kernel_size = kernel_size,\n",
    "#                         strides = 2,\n",
    "#                         activation ='relu',\n",
    "#                         padding ='same')(x)\n",
    "#     outputs = Conv2DTranspose(filters = 2,\n",
    "#                             kernel_size = kernel_size,\n",
    "#                             activation ='sigmoid',\n",
    "#                             padding ='same',\n",
    "#                             name ='decoder_output')(x)\n",
    "#     decoder = Model(latent_inputs, outputs, name ='decoder')\n",
    "\n",
    "#     autoencoder = Model(inputs, decoder(encoder(inputs)),\n",
    "#                     name ='autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7939752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gen_args = dict(rotation_range=30, fill_mode='nearest',\n",
    "#                      width_shift_range=0.2, height_shift_range=0.2,\n",
    "#                      horizontal_flip=True, vertical_flip=True,\n",
    "#                      shear_range=0.3\n",
    "# )\n",
    "# image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "# mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# seed = 1337\n",
    "# image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "# mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "# image_generator = image_datagen.flow(X_train, seed = seed, batch_size=64)\n",
    "# mask_generator = image_datagen.flow(y_train, seed = seed, batch_size=64)\n",
    "\n",
    "# train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "\n",
    "# # model = nn.autoencoder()\n",
    "# # model.compile(optimizer=RMSprop(), loss=MeanSquaredError(), metrics=[\"accuracy\"])\n",
    "# # model = nn.model_s()\n",
    "# # model.compile(optimizer='rmsprop', loss='mse', metrics=[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65d87dbd84d6699b6249583833f5a2128eb89a67d50c6406a8848397791798e4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('tf2.6.0': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
